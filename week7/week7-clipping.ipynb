{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 Clipping\n",
    "\n",
    "In this lesson we will learn how to to clip different geometries.\n",
    "\n",
    "## About the data\n",
    "\n",
    "We will use three datasets in this lesson. \n",
    "\n",
    "The first dataset is a [TIGER shapefile of the US states from the United States Census Bureau](https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.2022.html#list-tab-790442341). Follow these steps to download shapefile with the United States' states:\n",
    "\n",
    "You can check the [metadata for all the TIGER shapefiles here](https://www.census.gov/programs-surveys/geography/technical-documentation/complete-technical-documentation/tiger-geo-line.html). \n",
    "\n",
    "The second dataset we'll use is [Natural Earth's simple medium scale populated places dataset](https://www.naturalearthdata.com/downloads/50m-cultural-vectors/). We can obtain this dataset by downloading the shapefile (choose the one that says \"simple (less columns)\").\n",
    "\n",
    "The third dataset we'll use is [Natural Earth's road dataset](https://www.naturalearthdata.com/downloads/10m-cultural-vectors/roads/). \n",
    "We can obtain this dataset by downloading the shapefile \n",
    "\n",
    "We will combine these datasets to create the following map of infrastructure in Alaska:\n",
    "\n",
    "## Import data\n",
    "\n",
    "Let's start by loading our libraries and then importing the datasets we will use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "from shapely.geometry import box  # To create polygon bounding box\n",
    "\n",
    "pd.set_option(\"display.max.columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------------------------------\n",
    "# Import and simplify states polygons\n",
    "states = gpd.read_file(os.path.join('data', \n",
    "                                    'tl_2022_us_state', \n",
    "                                    'tl_2022_us_state.shp'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import Natural Earth populated places points\n",
    "places = gpd.read_file(os.path.join('data',\n",
    "                                    'ne_50m_populated_places_simple',\n",
    "                                    'ne_50m_populated_places_simple.shp')\n",
    "                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import ferry routes lines\n",
    "roads = gpd.read_file(os.path.join('data',\n",
    "                                   'ne_10m_roads',\n",
    "                                   'ne_10m_roads.shp')\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check-in\n",
    "Use a for loop to iterate over the three geo-dataframes we imported and change their column names to lower caps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = [states, places, roads]\n",
    "for df in list:\n",
    "    df.columns = df.columns.str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['scalerank', 'featurecla', 'type', 'sov_a3', 'note', 'edited', 'name',\n",
      "       'namealt', 'namealtt', 'routeraw', 'question', 'length_km', 'toll',\n",
      "       'ne_part', 'label', 'label2', 'local', 'localtype', 'localalt',\n",
      "       'labelrank', 'ignore', 'add', 'rwdb_rd_id', 'orig_fid', 'prefix',\n",
      "       'uident', 'continent', 'expressway', 'level', 'min_zoom', 'min_label',\n",
      "       'geometry'],\n",
      "      dtype='object')\n",
      "Index(['region', 'division', 'statefp', 'statens', 'geoid', 'stusps', 'name',\n",
      "       'lsad', 'mtfcc', 'funcstat', 'aland', 'awater', 'intptlat', 'intptlon',\n",
      "       'geometry'],\n",
      "      dtype='object')\n",
      "Index(['scalerank', 'natscale', 'labelrank', 'featurecla', 'name', 'namepar',\n",
      "       'namealt', 'nameascii', 'adm0cap', 'capalt', 'capin', 'worldcity',\n",
      "       'megacity', 'sov0name', 'sov_a3', 'adm0name', 'adm0_a3', 'adm1name',\n",
      "       'iso_a2', 'note', 'latitude', 'longitude', 'pop_max', 'pop_min',\n",
      "       'pop_other', 'rank_max', 'rank_min', 'meganame', 'ls_name', 'min_zoom',\n",
      "       'ne_id', 'geometry'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check this worked\n",
    "print(roads.columns)\n",
    "print(states.columns)\n",
    "print(places.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EDS-220 env",
   "language": "python",
   "name": "eds220-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
